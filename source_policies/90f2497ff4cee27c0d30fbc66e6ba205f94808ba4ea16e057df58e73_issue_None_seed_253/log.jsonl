{"setup": {"seed": 253, "load_seed": 42, "load": 0, "load_dir": 0, "load_dir_2": 0, "pseudo_thres": 10, "pseudo_interval": 150, "use_evo": 0, "setup": "metaworld", "relabel_num_tasks": 3, "relabel_range": 10, "load_log_std_bounds": [-20, 2], "base_path": "/data2/zj/NewMTRL", "save_dir": "${setup.base_path}/logs/${setup.id}", "device": "cuda:0", "id": "90f2497ff4cee27c0d30fbc66e6ba205f94808ba4ea16e057df58e73_issue_None_seed_253", "description": "Sample Task", "tags": null, "git": {"commit_id": "d52e812ab16b374de59381eb269cbbf4b0843e0e", "has_uncommitted_changes": null, "issue_id": null}, "date": "2022-02-19 08:57:22", "slurm_id": "-1", "debug": {"should_enable": false}}, "experiment": {"name": "metaworld", "builder": {"_target_": "mtrl.experiment.${experiment.name}.Experiment"}, "init_steps": 5000, "num_train_steps": 3000000, "eval_freq": 10000, "num_eval_episodes": 1, "should_resume": true, "save": {"model": {"retain_last_n": 1}, "buffer": {"should_save": true, "size_per_chunk": 10000, "num_samples_to_save": -1}}, "save_dir": "${setup.save_dir}", "save_video": false, "envs_to_exclude_during_training": null}, "agent": {"name": "state_sac", "encoder_feature_dim": 50, "num_layers": 0, "num_filters": 0, "builder": {"_target_": "mtrl.agent.sac.Agent", "actor_cfg": "${agent.actor}", "critic_cfg": "${agent.critic}", "multitask_cfg": "${agent.multitask}", "alpha_optimizer_cfg": "${agent.optimizers.alpha}", "actor_optimizer_cfg": "${agent.optimizers.actor}", "critic_optimizer_cfg": "${agent.optimizers.critic}", "discount": 0.99, "init_temperature": 1.0, "actor_update_freq": 1, "critic_tau": 0.005, "critic_target_update_freq": 1, "encoder_tau": 0.05}, "actor": {"_target_": "mtrl.agent.components.actor.Actor", "num_layers": 3, "hidden_dim": 400, "log_std_bounds": [-20, 2], "encoder_cfg": "${agent.encoder}", "multitask_cfg": "${agent.multitask}"}, "critic": {"_target_": "mtrl.agent.components.critic.Critic", "hidden_dim": "${agent.actor.hidden_dim}", "num_layers": "${agent.actor.num_layers}", "encoder_cfg": "${agent.encoder}", "multitask_cfg": "${agent.multitask}"}, "encoder": {"type_to_select": "identity", "identity": {"type": "identity", "feature_dim": "${agent.encoder_feature_dim}"}, "feedforward": {"type": "feedforward", "hidden_dim": 50, "num_layers": 2, "feature_dim": "${agent.encoder_feature_dim}", "should_tie_encoders": true}, "film": {"type": "film", "hidden_dim": 50, "num_layers": 2, "feature_dim": "${agent.encoder_feature_dim}", "should_tie_encoders": true}, "moe": {"type": "moe", "encoder_cfg": {"type": "feedforward", "hidden_dim": 50, "num_layers": 2, "feature_dim": "${agent.encoder_feature_dim}", "should_tie_encoders": true}, "num_experts": 9, "task_id_to_encoder_id_cfg": {"mode": "cluster", "num_envs": "${env.num_envs}", "gate": {"embedding_dim": 50, "hidden_dim": 50, "num_layers": 2, "temperature": 1.0, "should_use_soft_attention": false, "topk": 2, "task_encoder_cfg": {"should_use_task_encoding": true, "should_detach_task_encoding": true}}, "attention": {"embedding_dim": 50, "hidden_dim": 50, "num_layers": 2, "temperature": 1.0, "should_use_soft_attention": true, "task_encoder_cfg": {"should_use_task_encoding": true, "should_detach_task-encoding": true}}, "cluster": {"env_name": "${env.name}", "task_description": "${env.description}", "ordered_task_list": "${env.ordered_task_list}", "mapping_cfg": "${agent.task_to_encoder_cluster}", "num_eval_episodes": "${experiment.num_eval_episodes}", "batch_size": "${replay_buffer.batch_size}"}, "identity": {"num_eval_episodes": "${experiment.num_eval_episodes}", "batch_size": "${replay_buffer.batch_size}"}, "ensemble": {"num_eval_episodes": "${experiment.num_eval_episodes}", "batch_size": "${replay_buffer.batch_size}"}}}, "factorized_moe": {"type": "fmoe", "encoder_cfg": "${agent.encoder.feedforward}", "num_factors": 2, "num_experts_per_factor": [5, 5]}, "pixel": {"type": "pixel", "feature_dim": "${agent.encoder_feature_dim}", "num_filters": "${agent.num_filters}", "num_layers": "${agent.num_layers}"}}, "transition_model": {"_target_": "mtrl.agent.components.transition_model.make_transition_model", "transition_cfg": {"type": "", "feature_dim": "${agent.encoder_feature_dim}", "layer_width": 512}, "multitask_cfg": "${agent.multitask}"}, "mask": {"num_tasks": "${env.num_envs}", "num_eval_episodes": "${experiment.num_eval_episodes}", "batch_size": "${replay_buffer.batch_size}"}, "multitask": {"num_envs": 3, "should_use_disentangled_alpha": true, "should_use_task_encoder": false, "should_use_multi_head_policy": true, "should_use_disjoint_policy": true, "task_encoder_cfg": {"model_cfg": {"_target_": "mtrl.agent.components.task_encoder.TaskEncoder", "pretrained_embedding_cfg": {"should_use": false, "path_to_load_from": "/private/home/sodhani/projects/mtrl/metadata/task_embedding/roberta_small/${env.name}.json", "ordered_task_list": "${env.ordered_task_list}"}, "num_embeddings": "${agent.multitask.num_envs}", "embedding_dim": 50, "hidden_dim": 50, "num_layers": 2, "output_dim": 50}, "optimizer_cfg": "${agent.optimizers.actor}", "losses_to_train": ["critic", "transition_reward", "decoder", "task_encoder"]}, "multi_head_policy_cfg": {"mask_cfg": "${agent.mask}"}, "actor_cfg": {"should_condition_model_on_task_info": false, "should_condition_encoder_on_task_info": false, "should_concatenate_task_info_with_encoder": false, "moe_cfg": {"mode": "soft_modularization", "num_experts": 4, "should_use": false}}, "critic_cfg": "${agent.multitask.actor_cfg}"}, "gradnorm": {"alpha": 1.0}, "task_to_encoder_cluster": {"mt10": {"cluster": {"action_close": ["close"], "action_default": ["insert", "pick and place", "press", "reach"], "action_open": ["open"], "action_push": ["push"], "object_default": ["button", "door", "peg", "revolving joint"], "object_drawer": ["drawer"], "object_goal": ["goal"], "object_puck": ["puck"], "object_window": ["window"]}}, "mt50": {"cluster": {"action_close": ["close"], "action_default": ["insert", "pick and place", "press", "reach"], "action_open": ["open"], "action_push": ["push"], "object_default": ["button", "door", "peg", "revolving joint"], "object_drawer": ["drawer"], "object_goal": ["goal"], "object_puck": ["puck"], "object_window": ["window"]}}}, "optimizers": {"actor": {"_target_": "torch.optim.Adam", "lr": 0.0003, "betas": [0.9, 0.999]}, "alpha": {"_target_": "torch.optim.Adam", "lr": 0.0003, "betas": [0.9, 0.999]}, "critic": {"_target_": "torch.optim.Adam", "lr": 0.0003}, "decoder": {"_target_": "torch.optim.Adam", "lr": 0.0003, "betas": [0.9, 0.999], "weight_decay": 1e-07}, "encoder": {"_target_": "torch.optim.Adam", "lr": 0.0003, "betas": [0.9, 0.999]}}}, "env": {"name": "metaworld-mt3", "num_envs": 30, "tasks": ["reach-v2", "push-v2", "pick-place-v2"], "ids": [0, 1, 2], "benchmark": {"_target_": "metaworld.MT10"}, "builder": {"make_kwargs": {"should_perform_reward_normalization": false}}, "dummy": {"_target_": "metaworld.MT1", "env_name": "pick-place-v1"}, "description": {"reach-v1": "Reach a goal position. Randomize the goal positions.", "push-v1": "Push the puck to a goal. Randomize puck and goal positions.", "pick-place-v1": "Pick and place a puck to a goal. Randomize puck and goal positions.", "door-open-v1": "Open a door with a revolving joint. Randomize door positions.", "drawer-open-v1": "Open a drawer. Randomize drawer positions.", "drawer-close-v1": "Push and close a drawer. Randomize the drawer positions.", "button-press-topdown-v1": "Press a button from the top. Randomize button positions.", "peg-insert-side-v1": "Insert a peg sideways. Randomize peg and goal positions.", "window-open-v1": "Push and open a window. Randomize window positions.", "window-close-v1": "Push and close a window. Randomize window positions."}, "ordered_task_list": null, "train": [0, 1, 2]}, "replay_buffer": {"_target_": "mtrl.replay_buffer.ReplayBuffer", "env_obs_shape": null, "action_shape": null, "capacity": 1000000, "batch_size": 1280}, "logger": {"_target_": "mtrl.logger.Logger", "logger_dir": "${setup.save_dir}", "use_tb": false}, "metrics": {"train": [["episode", "E", "int", "average"], ["step", "S", "int", "average"], ["duration", "D", "time", "average"], ["episode_reward", "R", "float", "average"], ["success", "Su", "float", "average"], ["batch_reward", "BR", "float", "average"], ["actor_loss", "ALOSS", "float", "average"], ["critic_loss", "CLOSS", "float", "average"], ["expert_kl", "EXPERT_KL", "float", "average"], ["weight_0", "W_0", "float", "average"], ["weight_1", "W_1", "float", "average"], ["weight_2", "W_2", "float", "average"], ["weight_3", "W_3", "float", "average"], ["weight_4", "W_4", "float", "average"], ["weight_5", "W_5", "float", "average"], ["weight_6", "W_6", "float", "average"], ["weight_7", "W_7", "float", "average"], ["weight_8", "W_8", "float", "average"], ["weight_9", "W_9", "float", "average"], ["weight_10", "W_10", "float", "average"], ["weight_11", "W_11", "float", "average"], ["weight_12", "W_12", "float", "average"], ["weight_13", "W_13", "float", "average"], ["weight_14", "W_14", "float", "average"], ["weight_15", "W_15", "float", "average"], ["weight_16", "W_11", "float", "average"], ["weight_17", "W_12", "float", "average"], ["weight_18", "W_13", "float", "average"], ["weight_19", "W_14", "float", "average"], ["weight_20", "W_15", "float", "average"], ["significance", "SIG", "float", "average"], ["ae_loss", "RLOSS", "float", "average"], ["ae_transition_loss", null, "float", "average"], ["reward_loss", null, "float", "average"], ["actor_target_entropy", null, "float", "average"], ["actor_entropy", null, "float", "average"], ["alpha_loss", null, "float", "average"], ["alpha_value", null, "float", "average"], ["contrastive_loss", "MLOSS", "float", "average"], ["max_rat", "MR", "float", "average"], ["env_index", "ENV", "str", "constant"], ["episode_reward_env_index_", "R_", "float", "average"], ["success_env_index_", "Su_", "float", "average"], ["env_index_", "ENV_", "str", "constant"], ["batch_reward_agent_index_", null, "float", "average"], ["critic_loss_agent_index_", "AGENT_", "float", "average"], ["actor_distilled_agent_loss_agent_index_", null, "float", "average"], ["actor_loss_agent_index_", null, "float", "average"], ["actor_target_entropy_agent_index_", null, "float", "average"], ["actor_entropy_agent_index_", null, "float", "average"], ["alpha_loss_agent_index_", null, "float", "average"], ["alpha_value_agent_index_", null, "float", "average"], ["ae_loss_agent_index_", null, "float", "average"]], "eval": [["episode", "E", "int", "average"], ["step", "S", "int", "average"], ["episode_reward", "R", "float", "average"], ["env_index", "ENV", "str", "constant"], ["success", "Su", "float", "average"], ["episode_reward_env_index_", "R_", "float", "average"], ["success_env_index_", "Su_", "float", "average"], ["env_index_", "ENV_", "str", "constant"], ["batch_reward_agent_index_", "AGENT_", "float", "average"]]}, "logbook": {"_target_": "ml_logger.logbook.make_config", "write_to_console": false, "logger_dir": "${setup.save_dir}", "create_multiple_log_files": false}, "status": "RUNNING", "logbook_id": "0", "logbook_timestamp": "08:57:22AM CST Feb 19, 2022", "logbook_type": "metadata"}
